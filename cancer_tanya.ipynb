{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWwaOjPI2hnI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lm3_UsLc2pY6"
      },
      "outputs": [],
      "source": [
        "#Set display Option\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L2353YL2vKI"
      },
      "outputs": [],
      "source": [
        "#Load Dataset\n",
        "from sklearn.datasets import load_breast_cancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2yQkpFG2yBT",
        "outputId": "eb60b120-b0a9-4b98-95c3-59f837187495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
            "        1.189e-01],\n",
            "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
            "        8.902e-02],\n",
            "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
            "        8.758e-02],\n",
            "       ...,\n",
            "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
            "        7.820e-02],\n",
            "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
            "        1.240e-01],\n",
            "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
            "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error',\n",
            "       'fractal dimension error', 'worst radius', 'worst texture',\n",
            "       'worst perimeter', 'worst area', 'worst smoothness',\n",
            "       'worst compactness', 'worst concavity', 'worst concave points',\n",
            "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ],
      "source": [
        "data = load_breast_cancer()\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOKlEC_520dz",
        "outputId": "f3f9c895-47d4-49d1-a7a3-cbd60d586d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
            " ...\n",
            " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
            " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
            " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
          ]
        }
      ],
      "source": [
        "x = data.data\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-QOC_ae24Lr",
        "outputId": "8934f649-ab8b-4cf4-b9b2-42d8e7597443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "y = data.target\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dc7-FLy27T_",
        "outputId": "84475104-39b9-4cba-c678-f98219f3069b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#shape of x\n",
        "x.shape #features = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oK0krPh2-AL",
        "outputId": "bb8648d4-2c24-40bf-c68e-4ffad9459812"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#shape of y\n",
        "y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha2KNSea3ALe"
      },
      "outputs": [],
      "source": [
        "#Standardize data to normal/guassian distribution\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSD2FXGJ3GSm"
      },
      "outputs": [],
      "source": [
        "# x_scaled =StandardScaler().fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4X_wqLf3Tg8",
        "outputId": "a93c7107-5991-4cf2-8963-db1afa28851c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of Outliers in first column:  [  0   3   9  12  14  23  25  31  35  42  60  68  71  72  78  82  83 105\n",
            " 108 112 116 119 122 138 146 151 152 176 180 181 190 192 202 203 212 213\n",
            " 219 232 236 239 258 259 265 288 290 314 318 323 339 345 351 352 368 370\n",
            " 376 379 388 389 400 416 417 430 461 473 503 504 505 521 557 559 561 562\n",
            " 567 568]\n",
            "Indices of Outliers in second column:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 28 29]\n"
          ]
        }
      ],
      "source": [
        "#OUTLIER DETECTION\n",
        "\n",
        "##Z-SCORE\n",
        "from scipy import stats\n",
        "\n",
        "z_scores = np.abs(stats.zscore(x_scaled))\n",
        "threshold = 3\n",
        "outliers = np.where(z_scores > 3)\n",
        "\n",
        "print(\"Indices of Outliers in first column: \", np.unique(outliers[0]))\n",
        "\n",
        "print(\"Indices of Outliers in second column: \", np.unique(outliers[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WFGfWQC3X3j",
        "outputId": "5e2d64a6-6857-4e02-e54d-19524f483d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of Outliers:  (array([  0,   1,   2,   3,   4,   5,   8,   9,  12,  14,  15,  18,  22,\n",
            "        23,  24,  25,  26,  27,  30,  31,  33,  34,  35,  38,  41,  42,\n",
            "        53,  56,  60,  62,  63,  68,  70,  71,  72,  76,  77,  78,  82,\n",
            "        83,  95, 105, 108, 110, 111, 112, 116, 118, 119, 121, 122, 136,\n",
            "       138, 145, 146, 147, 150, 151, 152, 156, 161, 162, 164, 168, 173,\n",
            "       176, 180, 181, 185, 190, 192, 196, 199, 202, 203, 210, 212, 213,\n",
            "       214, 218, 219, 229, 232, 236, 239, 242, 245, 250, 252, 254, 256,\n",
            "       257, 258, 259, 262, 265, 272, 273, 275, 288, 290, 300, 302, 314,\n",
            "       318, 323, 329, 332, 335, 337, 339, 343, 345, 351, 352, 366, 368,\n",
            "       369, 370, 372, 373, 376, 379, 388, 389, 391, 393, 400, 416, 417,\n",
            "       424, 430, 433, 443, 449, 450, 455, 460, 461, 465, 468, 469, 471,\n",
            "       473, 485, 489, 492, 498, 503, 504, 505, 507, 520, 521, 528, 533,\n",
            "       535, 537, 538, 539, 553, 556, 557, 559, 561, 562, 563, 564, 565,\n",
            "       567, 568]),)\n"
          ]
        }
      ],
      "source": [
        "##IQR(Inter Quartile Range)\n",
        "Q1 = np.percentile(x_scaled, 25, axis = 0)\n",
        "Q3 = np.percentile(x_scaled, 75, axis = 0)\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "outliers1 = ((x_scaled < (Q1 - 1.5* IQR)) | (x_scaled > (Q3 + 1.5*IQR)))\n",
        "outliers1 = ((x_scaled < (Q1 - 1.5* IQR)) | (x_scaled > (Q3 + 1.5*IQR))).any(axis=1) #visualize outliers in one dimension\n",
        "\n",
        "print(\"Indices of Outliers: \", np.where(outliers1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8zvJkil3hLm"
      },
      "outputs": [],
      "source": [
        "##ISOLATION FOREST METHOD\n",
        "from sklearn.ensemble import IsolationForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD30lAlU3k0x"
      },
      "outputs": [],
      "source": [
        "#Initialise Model\n",
        "iso_forest = IsolationForest(contamination = 0.01)\n",
        "#conatmination parameter determines the maximum outlier, here 0.01 means 1% of the outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_YwEv0h30a6"
      },
      "outputs": [],
      "source": [
        "prediction = iso_forest.fit_predict(x_scaled)\n",
        "#1s are normal, -1s are outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K967bOyl35MI"
      },
      "outputs": [],
      "source": [
        "# predictions = IsolationForest(contamination = 0.1).fit_predict(x_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA521s_-39LR",
        "outputId": "f0ed7a79-ebd5-4633-d8ee-17743c6748f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of Outliers:  [  3  78 108 122 212 461]\n"
          ]
        }
      ],
      "source": [
        "#get outliers\n",
        "outliers2_indices = np.where(prediction == -1)\n",
        "print(\"Indices of Outliers: \", outliers2_indices[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ra7dcJ63_6n"
      },
      "outputs": [],
      "source": [
        "##LOCAL OUTLIER FACTOR METHOD\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "LOF = LocalOutlierFactor(n_neighbors=20, contamination=0.01) #initialization\n",
        "\n",
        "predict = LOF.fit_predict(x_scaled)\n",
        "\n",
        "# LOF = LocalOutlierFactor(n_neighbors=20, contamination=0.01).fit_predict(x_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WKDfjap4FV-",
        "outputId": "f7791046-c81b-49b0-def1-79f218a6f45e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of Outliers:  (array([ 38, 152, 192, 212, 213, 461]),)\n"
          ]
        }
      ],
      "source": [
        "#get outliers\n",
        "outliers3 = np.where(predict == -1)\n",
        "print(\"Indices of Outliers: \", outliers3)\n",
        "# print(\"Indices of Outliers: \", outliers3[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8ILwoQS4LaB"
      },
      "outputs": [],
      "source": [
        "##DBSCAN\n",
        "from sklearn.cluster import DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaG16a0f4OMc"
      },
      "outputs": [],
      "source": [
        "DBSCAN = DBSCAN(eps = 5, min_samples = 5)\n",
        "clusters = DBSCAN.fit_predict(x_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q6YLkHS4RJ0"
      },
      "outputs": [],
      "source": [
        "# clusters = DBSCAN(eps = 0.5, min_samples = 5).fit_predict(x_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG87SW154VYg",
        "outputId": "0bded867-3ae0-469d-8823-775e6c84fe32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of Outliers: (array([  3,   9,  12,  42,  68,  71,  78,  83, 108, 122, 138, 152, 176,\n",
            "       190, 192, 212, 213, 258, 288, 290, 314, 461, 504, 505]),)\n"
          ]
        }
      ],
      "source": [
        "#get outliers\n",
        "outliers4_indices = np.where(clusters == -1)\n",
        "print(\"Indices of Outliers:\", outliers4_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R85vqfE_4Y2u"
      },
      "outputs": [],
      "source": [
        "##ONE-CLASS SVM\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "oc_svm = OneClassSVM(nu=0.01, kernel='rbf', gamma=0.1)\n",
        "oc_svm.fit(x_scaled)\n",
        "predict1 = oc_svm.predict(x_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnBwnkMj4dvr",
        "outputId": "951ec3df-9f61-4877-c719-ba1cacc4404f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of Outliers: (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
            "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
            "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  39,\n",
            "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
            "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
            "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
            "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
            "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
            "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
            "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
            "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
            "       144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157,\n",
            "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
            "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
            "       184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197,\n",
            "       198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
            "       211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
            "       226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
            "       239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
            "       252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
            "       265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
            "       278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
            "       291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
            "       304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
            "       317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
            "       330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
            "       343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
            "       356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
            "       369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
            "       382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
            "       395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
            "       408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
            "       421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
            "       434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
            "       447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
            "       460, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
            "       474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
            "       487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499,\n",
            "       500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512,\n",
            "       513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525,\n",
            "       526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538,\n",
            "       539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
            "       552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,\n",
            "       565, 566, 567, 568]),)\n"
          ]
        }
      ],
      "source": [
        "#get outliers\n",
        "outliers5_indices = np.where(predict == 1 )\n",
        "print(\"Indices of Outliers:\", outliers5_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N2Y8Zto4gQ_"
      },
      "outputs": [],
      "source": [
        "## MOHALANOBIS DISTANCE\n",
        "from scipy.spatial import distance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvZkbrC_4jUm"
      },
      "outputs": [],
      "source": [
        "#inverse covariance matrix\n",
        "cov_matrix = np.cov(x_scaled.T)\n",
        "inv_cov_matrix = np.linalg.inv(cov_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB-TQV_K4lbN"
      },
      "outputs": [],
      "source": [
        "# Calculate Distance\n",
        "mean_vals = np.mean(x_scaled, axis=0)\n",
        "distance = np.array([distance.mahalanobis(x, mean_vals, inv_cov_matrix)for x in x_scaled])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exL47juD4oe0"
      },
      "outputs": [],
      "source": [
        "# store = []\n",
        "# for x in x_scaled:\n",
        "#     store.append(distance.mahalanobis(x, mean_vals, inv_cov_matrix))\n",
        "# print(len(store))\n",
        "\n",
        "# mahalanobis_distance1 = np.array(store)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CdID_uH4rOG",
        "outputId": "6e9caa02-bd9e-4e9d-c57c-b6e2f375e907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices Of Outliers:  [  9  12  38  68  71  78 122 152 192 212 213 265 290 461]\n"
          ]
        }
      ],
      "source": [
        "threshold = np.mean(distance) + 3 * np.std(distance)\n",
        "outliers6_indices = np.where(distance > threshold)\n",
        "print(\"Indices Of Outliers: \", outliers6_indices[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHV7rpqa5Wf2",
        "outputId": "aa17eb7d-a2ac-4be4-8c5b-32b9c117116c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhYcnVu24uNC"
      },
      "outputs": [],
      "source": [
        "##AUTOENCODER\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61lJliDd4wy6",
        "outputId": "d5ff0305-b95b-4163-f5ba-8018490fb690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 2s 10ms/step - loss: 1.0257 - val_loss: 0.9056\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c782680ff10>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#define autoencoder architect\n",
        "model = Sequential([\n",
        "    Input(shape=(x_scaled.shape[1]), ),\n",
        "          Dense(16, activation ='relu'),\n",
        "          Dense(8, activation = 'relu'),\n",
        "          Dense(4, activation = 'relu'),\n",
        "          Dense(2,activation='relu'), #compressed representation\n",
        "          Dense(4, activation='relu'),\n",
        "          Dense(8, activation = 'relu'),\n",
        "          Dense(16, activation='relu'),\n",
        "          Dense(x_scaled.shape[1], activation = 'linear') #reconstruction\n",
        "          ])\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'mse')\n",
        "model.fit(x_scaled, x_scaled, epochs=1, batch_size=16, validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh_EzWUn44i7",
        "outputId": "910ef19e-be0c-48d7-8a3e-88b2e5e5dadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "#predict the reconstruction error\n",
        "reconstruction = model.predict(x_scaled)\n",
        "mse = np.mean(np.power(x_scaled - reconstruction, 2), axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phPKqERr5AE4",
        "outputId": "9baa1864-63fb-4585-8e5f-4311376ec36a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of Outliers:  [  3  78 122 152 212 461]\n"
          ]
        }
      ],
      "source": [
        "#Detect Outliers\n",
        "mse_threshold = np.quantile(mse, 0.99)\n",
        "outliers7_indices = np.where(mse > mse_threshold)\n",
        "print('Indices of Outliers: ', outliers7_indices[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxFF3zU863La"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVmAsEjT5CTV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}